# Crawling_크롤링

### 1. 개요

- 크롤링 : 데이터를 불러오는 것

- 파싱 : 크롤링한 데이터에서 원하는 정보를 뽑아내는 것 (웹의 응답)

### 2. 웹에서 데이터 수집하는 방법

- 목적 : 분석에 필요한 데이터 수집
  
  1. 웹사이트 직접 접근
  - 원하는 만큼 데이터 수집할 수 있으나, 직접 가공해야 함.     
  
  - 한계 : 법적 문제 발생 / UI 변경 시, 모두 수정해야 함
  2. <mark>API 호출</mark> 👈 **추천**!
  - 한계 : 제한된 용량 및 유료화
  
  - 상태코드를 유의해야 함 : 200 이 크롤링 가능

- 취준생을 위한 데이터 수집 : API 방식 추천

### 3. 크롤링 할 때 주의사항

- 웹사이트 직접 접근 시, `robots.txt` 확인 필수
  
  - 각 사이트마다 허용범위가 다 다름
  
  - 계속 수집 시, IP 차단 가능성 존재

### 4. 웹 크롤링 프로세스

| 절차  | 내용  | 주요 파이썬 라이브러리                                              |
| --- | --- | --------------------------------------------------------- |
|     |     | - request<br/>- selenium<br/>- scrapy (처음 배울 때 약간 허들이 있음) |
|     |     |                                                           |
|     |     |                                                           |
|     |     |                                                           |

#### 크롤링을 위해 꼭 알아야 할 것

- 크롬 개발자 도구

- 문자열 처리(정규표현식)

- API 문서 확인

- 인코딩 이슈

---

## 크롤링 시작하기

### API 공식문서 확인
